{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d802515",
   "metadata": {},
   "source": [
    "# NJU dataset Spatial MAPPing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ffadc",
   "metadata": {},
   "source": [
    "### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2495f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './learnable_spatial_mapping/')\n",
    "from learnable_spatial_mapping.LSM import deepNetwork as lsm_network\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# eeg = torch.randn(256, 32, 128*4, 8).to(device)\n",
    "# numCategories = 2\n",
    "# numConvolutinFilter = [8, 8, 12]\n",
    "# winlen = 2\n",
    "# numFCNeurons = [256, numCategories]\n",
    "# imageSize = (12, 12)\n",
    "# imageKernelSize = (13, 3, 3)\n",
    "\n",
    "# model = lsm_network(\n",
    "#     eeg,\n",
    "#     numConvFilter=numConvolutinFilter,\n",
    "#     winlen=winlen,\n",
    "#     numFCNeurons=numFCNeurons,\n",
    "#     numGroup=numCategories,\n",
    "#     enableMaxPool=False,\n",
    "#     imageSize=imageSize,\n",
    "#     imageKernelSize=imageKernelSize,\n",
    "#     device=device,\n",
    "# )\n",
    "\n",
    "# # print(summary(model, input_size=[(256, 32, 128*4, 8)], col_names=[\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\"]))\n",
    "\n",
    "# # \"\"\" ART Test \"\"\"\n",
    "# with torch.no_grad():\n",
    "#     start_time = time.time()\n",
    "#     for i in range(0, 5):\n",
    "#         output = model(eeg)\n",
    "#     end_time = time.time()\n",
    "#     print(f\"Training Time ={end_time-start_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85128d",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './learnable_spatial_mapping/')\n",
    "from learnable_spatial_mapping.LSM import deepNetwork as lsm_network\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Variables\n",
    "window_len_sec = 10\n",
    "choice_direction = 90\n",
    "\n",
    "# 使用範例\n",
    "path = \"./NJUNCA_preprocessed_arte_removed/\"\n",
    "expinfo_path = path + \"expinfomat_csvs/\"\n",
    "mat_files = [f for f in os.listdir(path) if f.endswith('.mat')]\n",
    "print(mat_files)    # 前兩個是info資料從第三個開始讀\n",
    "\n",
    "subjects = 21\n",
    "fs = 128  # sampling frequency\n",
    "window_size = fs * window_len_sec  # 512\n",
    "channels = 32  # assume full 32 channels\n",
    "count = 0\n",
    "side_dict = {\n",
    "    \"right\": 0,\n",
    "    \"left\": 1,\n",
    "}\n",
    "\n",
    "# Load data\n",
    "all_segments = []\n",
    "all_labels = []\n",
    "all_trials = []\n",
    "pre_trial_idx = 0\n",
    "\n",
    "for subj in range(2, subjects):\n",
    "    data_path = path + mat_files[subj]\n",
    "    file = h5py.File(data_path, 'r')\n",
    "    csv_path = expinfo_path + mat_files[subj].replace('.mat', '.csv')\n",
    "    df = pd.read_csv(csv_path)['attended_lr']\n",
    "\n",
    "    ref_data = file['data']\n",
    "    ref_eeg = ref_data['eeg']\n",
    "    ref_leftangle = ref_data['event']['leftWav']\n",
    "    ref_rightangle = ref_data['event']['rightWav']\n",
    "    ref_attenside = ref_data['event']['eeg']\n",
    "    trials = len(ref_eeg[:])\n",
    "\n",
    "    for trial in range(trials):\n",
    "        try:\n",
    "            left_angel_reg = file[ref_leftangle['value'][trial][0]]\n",
    "            left_angel = file[left_angel_reg[0][0]][0][0]\n",
    "            right_angel_reg = file[ref_rightangle['value'][trial][0]]\n",
    "            right_angel = file[right_angel_reg[0][0]][0][0]\n",
    "\n",
    "            if (left_angel*-1) != right_angel:\n",
    "                # print(f\"{mat_files[subj]}-{trial}: {left_angel}/{right_angel} not the same angle \")\n",
    "                continue\n",
    "            # if abs(right_angel) != 90:\n",
    "            #     print(f\"{mat_files[subj]}-{trial}: {left_angel}/{right_angel} not 90 degree\")\n",
    "            #     continue\n",
    "            print(f\"{mat_files[subj]}-{trial}: {left_angel}/{right_angel}\")\n",
    "            ref = ref_eeg[trial][0]\n",
    "            eeg_data = np.array(file[ref][:]) # shape: 32, time\n",
    "            trial_len = eeg_data.shape[1]\n",
    "            \n",
    "            # Segment into 4-second windows (non-overlapping)\n",
    "            n_windows = trial_len // window_size\n",
    "            \n",
    "            for win in range(n_windows):\n",
    "                segment = eeg_data[:, win * window_size : (win + 1) * window_size]  # shape: (channels, 512)\n",
    "                count += 1\n",
    "                all_segments.append(segment)\n",
    "                all_labels.append(side_dict[df[trial]])\n",
    "\n",
    "            # write trial info dict\n",
    "            trial_info = {\n",
    "                \"subject_name\": mat_files[subj].split('.')[0],\n",
    "                \"trial\":trial,\n",
    "                \"attention_side\": df[trial],\n",
    "                \"left_angel\": left_angel,\n",
    "                \"right_angel\": right_angel,\n",
    "                \"trial_start\": pre_trial_idx,\n",
    "                \"trial_end\": count,\n",
    "            }\n",
    "            all_trials.append(trial_info)\n",
    "            pre_trial_idx = count \n",
    "        except:\n",
    "            print(mat_files[subj], trial, 'load error')\n",
    "    print(f\"{mat_files[subj]} cumulated segments:{count}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.stack(all_segments)  # shape: (total_segments, channels, 512)\n",
    "y = np.array(all_labels)    # shape: (total_segments,)\n",
    "\n",
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "\n",
    "group_ = [(2, 7), (8, 15), (16, 19), (21, 23), (25, 27)]  # 5 groups\n",
    "group_index_list = [[] for _ in range(len(group_))]      # list of 5 empty lists\n",
    "\n",
    "cum_trials = 0 \n",
    "for idx, info_dict in enumerate(all_trials):\n",
    "    # print(f\"{idx}-{info_dict['subject_name']}/{info_dict['trial']} - cumulated trials rate:{info_dict['trial_end']/count}\")\n",
    "    if choice_direction != 0:\n",
    "        if abs(info_dict['left_angel']) != choice_direction:\n",
    "            continue\n",
    "\n",
    "    subject_int = int(info_dict['subject_name'].replace('S', ''))\n",
    "\n",
    "    # 分配到對應的 group\n",
    "    for group_id, (low, high) in enumerate(group_):\n",
    "        if low <= subject_int <= high:\n",
    "            trial_range = range(info_dict['trial_start'], info_dict['trial_end'])\n",
    "            # print(info_dict['trial_start'], info_dict['trial_end'])\n",
    "            cum_trials += len(trial_range)\n",
    "            group_index_list[group_id].extend(trial_range)\n",
    "            break\n",
    "\n",
    "print(f\"Total trials: {cum_trials}\")\n",
    "cum_ratio = 0\n",
    "for idx, g_l in enumerate(group_index_list):\n",
    "    trial_ratio = len(g_l)/cum_trials\n",
    "    cum_ratio += trial_ratio\n",
    "    print(f\"Group {idx+1}:(S{group_[idx][0]:02d}~S{group_[idx][1]:02d}) | total trials:{len(g_l)}, trials ratio:{trial_ratio*100:.1f}%, cumulated ratio:{cum_ratio*100:.1f}%\")\n",
    "    # print(len(g_l), trial_ratio, cum_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a0ca9",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "group_acc_list = []\n",
    "pred_list = []\n",
    "true_list = []\n",
    "\n",
    "for valid_group in range(len(group_index_list)):\n",
    "    print(f\"--------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    print(f\"\\nGroup:{valid_group}\\n\")\n",
    "    print(f\"--------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    test_idx = group_index_list[valid_group]\n",
    "    train_idx = [i for g, indices in enumerate(group_index_list) if g != valid_group for i in indices]\n",
    "\n",
    "    X_train = X[train_idx].copy()\n",
    "    X_test = X[test_idx].copy()\n",
    "    train_y = y[train_idx]\n",
    "    test_y = y[test_idx]\n",
    "\n",
    "    print(f\"{X_train.shape} - {X_test.shape} - {train_y.shape} - {test_y.shape}\")\n",
    "    train_dataset = EEGDataset(X_train, train_y)\n",
    "    test_dataset = EEGDataset(X_test, test_y)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    val_acc, val_pred, val_true = run_train(train_loader, val_loader, winlen=window_len_sec, batch_size=batch_size, num_epochs=num_epochs)\n",
    "\n",
    "    print(f\"Group {valid_group} Accuracy: {val_acc:.4f}\")\n",
    "    group_acc_list.append(val_acc)\n",
    "    pred_list.extend(val_pred)\n",
    "    true_list.extend(val_true)\n",
    "\n",
    "# === Summary ===\n",
    "group_acc_array = np.array(group_acc_list)\n",
    "std_acc = group_acc_array.std()\n",
    "acc = accuracy_score(true_list, pred_list)\n",
    "\n",
    "print(\"\\n=== Cross-Validation Summary ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Group Std  Accuracy: {std_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3d217",
   "metadata": {},
   "source": [
    "### Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from model.utils import *\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y, apply_filter=True):\n",
    "        self.X = X  # shape: (N, 32, 512)\n",
    "        self.y = y  # shape: (N,)\n",
    "        self.apply_filter = apply_filter\n",
    "        if self.apply_filter:\n",
    "            self.filter = filterBank()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg = self.X[idx]  # shape: (32, 512)\n",
    "        label = self.y[idx]\n",
    "\n",
    "        if self.apply_filter:\n",
    "            eeg_filtered = self.filter.__step__(eeg)  # shape: (4, 32, 512)\n",
    "            eeg_filtered = np.transpose(eeg_filtered, (1, 2, 0))  # to (32, 512, 4)\n",
    "        else:\n",
    "            eeg_filtered = eeg  # shape: (32, 512)\n",
    "\n",
    "        return torch.from_numpy(eeg_filtered).float(), torch.tensor(label).long()\n",
    "    \n",
    "def run_train(train_loader, val_loader, winlen=2, batch_size=64, num_epochs=100, learning_rate = 1e-4, early_stop_patience=30):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # === Hyperparameters ===\n",
    "\n",
    "    l2_factor = 1e-5\n",
    "    lr_drop_factor = 0.5\n",
    "    patience = 10\n",
    "    cooldown = 0\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    eeg = torch.randn(256, 32, 128*winlen, 4).to(device)\n",
    "    numCategories = 2\n",
    "    numConvolutinFilter = [8, 8, 12]\n",
    "    numFCNeurons = [256, numCategories]\n",
    "    imageSize = (12, 12)\n",
    "    imageKernelSize = (13, 3, 3)\n",
    "\n",
    "    model = lsm_network(\n",
    "        eeg,\n",
    "        numConvFilter=numConvolutinFilter,\n",
    "        winlen=winlen,\n",
    "        numFCNeurons=numFCNeurons,\n",
    "        numGroup=numCategories,\n",
    "        enableMaxPool=False,\n",
    "        imageSize=imageSize,\n",
    "        imageKernelSize=imageKernelSize,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_factor)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=lr_drop_factor, patience=patience, cooldown=cooldown,\n",
    "        threshold=0.015, threshold_mode='abs', verbose=True\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_val_pred = []\n",
    "    best_val_true = []\n",
    "    epochs_since_improvement = 0  # <<< 用于early stopping\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, pred = out.max(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                _, pred = out.max(1)\n",
    "                val_correct += (pred == y).sum().item()\n",
    "                val_total += y.size(0)\n",
    "\n",
    "                val_preds.append(pred.cpu())\n",
    "                val_labels.append(y.cpu())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"[Epoch {epoch+1}] Val Acc: {val_acc:.4f}\")\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        # Save best model and predictions\n",
    "        if val_acc > best_val_acc + 1e-4:  # small epsilon to avoid float rounding issues\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            print(f\"Best model saved at epoch {epoch+1}\")\n",
    "            best_val_pred = torch.cat(val_preds).numpy()\n",
    "            best_val_true = torch.cat(val_labels).numpy()\n",
    "            epochs_since_improvement = 0  # <<< reset counter\n",
    "        else:\n",
    "            epochs_since_improvement += 1  # <<< increment counter\n",
    "            print(f\"No improvement for {epochs_since_improvement} epoch(s)\")\n",
    "\n",
    "        # === Early stopping condition ===\n",
    "        if epochs_since_improvement >= early_stop_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # === End of Training ===\n",
    "    return best_val_acc, best_val_pred, best_val_true\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
